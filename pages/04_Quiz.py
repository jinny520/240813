import streamlit as st
from langchain_core.output_parsers import StrOutputParser
from langchain_openai import ChatOpenAI, OpenAIEmbeddings  # OpenAIEmbeddings ì„í¬íŠ¸ ëˆ„ë½
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import PDFPlumberLoader
from langchain_community.vectorstores import FAISS
from langchain_core.runnables import RunnablePassthrough
from dotenv import load_dotenv
import os

# API KEY ì •ë³´ë¡œë“œ
load_dotenv()

# ìºì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
if not os.path.exists(".cache"):
    os.mkdir(".cache")

# íŒŒì¼ ì—…ë¡œë“œ ì „ìš© í´ë”
if not os.path.exists(".cache/files"):
    os.mkdir(".cache/files")

if not os.path.exists(".cache/embeddings"):
    os.mkdir(".cache/embeddings")

st.title("PDF ê¸°ë°˜ í€´ì¦ˆ ìƒì„±ê¸°ğŸ“šâ“")

# ì²˜ìŒ 1ë²ˆë§Œ ì‹¤í–‰í•˜ê¸° ìœ„í•œ ì½”ë“œ
if "pdf_retriever" not in st.session_state:
    st.session_state["pdf_retriever"] = None

# ì‚¬ì´ë“œë°” ìƒì„±
with st.sidebar:
    # íŒŒì¼ ì—…ë¡œë“œ
    uploaded_file = st.file_uploader("PDF íŒŒì¼ ì—…ë¡œë“œ", type=["pdf"])

    # ëª¨ë¸ ì„ íƒ ë©”ë‰´
    selected_model = st.selectbox(
        "LLM ì„ íƒ", ["gpt-4-turbo", "gpt-4o"], index=0
    )

    generate_quiz_btn = st.button("í€´ì¦ˆ ìƒì„±")

# íŒŒì¼ì„ ìºì‹œ ì €ì¥ ë° ì„ë² ë”© ìƒì„± (ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¬ëŠ” ì‘ì—…ì„ ì²˜ë¦¬í•  ì˜ˆì •)
@st.cache_resource(show_spinner="ì—…ë¡œë“œí•œ íŒŒì¼ì„ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤...")
def embed_file(file):
    file_content = file.read()
    file_path = f"./.cache/files/{file.name}"
    with open(file_path, "wb") as f:
        f.write(file_content)

    loader = PDFPlumberLoader(file_path)
    docs = loader.load()

    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)
    split_documents = text_splitter.split_documents(docs)

    embeddings = OpenAIEmbeddings(model="text-embedding-ada-002", openai_api_key=os.getenv("OPENAI_API_KEY"))

    vectorstore = FAISS.from_documents(documents=split_documents, embedding=embeddings)

    retriever = vectorstore.as_retriever()
    return retriever

# í€´ì¦ˆ ì²´ì¸ ìƒì„±
def create_quiz_chain(retriever, model_name="gpt-4-turbo"):
    quiz_prompt = "Generate a quiz question based on the following content:"
    llm = ChatOpenAI(model_name=model_name, temperature=0, openai_api_key=os.getenv("OPENAI_API_KEY"))
    
    chain = (
        {"context": retriever, "question": RunnablePassthrough()}
        | quiz_prompt
        | llm
        | StrOutputParser()
    )
    return chain

# íŒŒì¼ì´ ì—…ë¡œë“œ ë˜ì—ˆì„ ë•Œ
if uploaded_file:
    retriever = embed_file(uploaded_file)
    st.session_state["pdf_retriever"] = retriever
    st.success("PDF íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œ ë° ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.")

# í€´ì¦ˆ ìƒì„± ë²„íŠ¼ì´ ëˆŒë¦¬ë©´...
if generate_quiz_btn and st.session_state.get("pdf_retriever"):
    quiz_chain = create_quiz_chain(st.session_state["pdf_retriever"], model_name=selected_model)
    quiz_question = "Please generate a quiz question based on the PDF content."
    response = quiz_chain(quiz_question)
    st.write("ìƒì„±ëœ í€´ì¦ˆ ë¬¸ì œ:")
    st.write(response)
elif generate_quiz_btn:
    st.warning("ë¨¼ì € PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
